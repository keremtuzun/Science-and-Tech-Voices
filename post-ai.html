<!DOCTYPE html>
<html lang="tr">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Kurslar - Science & Tech Voices</title>
  <link rel="stylesheet" href="styles.css" />
  <script src="script.js" defer></script>
</head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-11TRNPH4W8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-11TRNPH4W8');
</script>
<body>
  <header class="site-header">
    <div class="container navbar">
      <a class="brand" href="index.html">
        <img src="logo.png" alt="Science & Tech Voices logo" class="site-logo">
        <span>Science & Tech Voices</span>
      </a>

      
      <nav class="navlinks">
        <a href="index.html">Ana Sayfa</a>
        <a href="conferences.html">Konferanslar</a>
        <a href="posts.html">YayÄ±nlar</a>
        <a href="courses.html">Kurslar</a>
        <a href="team.html">Ekibimiz</a>
        <button id="langButton" class="btn">English ğŸŒ</button>

      </nav>
      <button class="mobile-toggle btn">â˜°</button>
    </div>
  </header>

  <main class="container page">
    <h1>Yapay ZekÃ¢ EtiÄŸi: Kodun VicdanÄ± Olur mu?</h1>
    <p class="meta">Yazar: Science & Tech Voices Ekibi â€¢ 20 Ekim 2025</p>
    <img src="News_Image_-_2024-01-22T102627.569.png" alt="AI Ethics" class="post-cover">

    <article class="prose">

        <p>Yapay zekÃ¢ (YZ) artÄ±k yalnÄ±zca bilim kurgu romanlarÄ±nÄ±n deÄŸil, gÃ¼ndelik hayatÄ±n da bir parÃ§asÄ±. TelefonlarÄ±mÄ±zda, arama motorlarÄ±nda, hastanelerde, hatta adalet sistemlerinde bile YZâ€™nin kararlarÄ±yla karÅŸÄ±laÅŸÄ±yoruz. Peki, bu sistemler ne kadar â€œdoÄŸruâ€ karar veriyor? Daha da Ã¶nemlisi: Bir makinenin vicdanÄ± olabilir mi?</p>
  
        <h3>1. Kodla YazÄ±lan Kararlar</h3>
        <p>Bir yapay zekÃ¢ sistemi, Ã¶zÃ¼nde bir dizi algoritmadan ibaret. Karar verme sÃ¼reci, insanlar tarafÄ±ndan yazÄ±lmÄ±ÅŸ kodlara ve eÄŸitildiÄŸi verilere dayanÄ±yor. Ancak bu veriler kusursuz deÄŸil. OnlarÄ± biz insanlar Ã¼retiyoruz; Ã¶nyargÄ±larÄ±mÄ±z, yanlÄ±ÅŸ algÄ±larÄ±mÄ±z ve hatalarÄ±mÄ±z da bu verilere sÄ±zÄ±yor.</p>
  
        <p>SonuÃ§? Bir iÅŸe alÄ±m algoritmasÄ±nÄ±n kadÄ±n adaylarÄ± geri plana atmasÄ±, bir yÃ¼z tanÄ±ma sisteminin ten rengine gÃ¶re daha fazla hata yapmasÄ± veya bir haber Ã¶neri motorunun sadece belli gÃ¶rÃ¼ÅŸleri Ã¶ne Ã§Ä±karmasÄ±...</p>
  
        <p>Bu durum, etik sorularÄ± kaÃ§Ä±nÄ±lmaz hale getiriyor: EÄŸer kararlar hatalÄ±ysa, sorumlu kim? ProgramcÄ± mÄ±, ÅŸirket mi, yoksa algoritmanÄ±n kendisi mi?</p>
  
        <h3>2. Makine VicdanÄ± MÃ¼mkÃ¼n mÃ¼?</h3>
        <p>â€œVicdanâ€ kelimesi, ahlaki farkÄ±ndalÄ±k ve empatiyi Ã§aÄŸrÄ±ÅŸtÄ±rÄ±r â€” yani tamamen insana Ã¶zgÃ¼ Ã¶zellikleri. Yapay zekÃ¢lar bugÃ¼n duygulara sahip deÄŸil; yalnÄ±zca olasÄ±lÄ±k hesaplarÄ±na ve istatistiklere gÃ¶re davranÄ±yorlar.</p>
  
        <p>Yine de, araÅŸtÄ±rmacÄ±lar â€œetik algoritmalarâ€ geliÅŸtirmeye Ã§alÄ±ÅŸÄ±yor. Ã–rneÄŸin, bir sÃ¼rÃ¼cÃ¼sÃ¼z araba bir kaza anÄ±nda kime Ã¶ncelik vermeli? Bu, modern Ã§aÄŸÄ±n <em>trolley problem</em>â€™ine dÃ¶nÃ¼ÅŸmÃ¼ÅŸ durumda.</p>
  
        <p>Kimi projeler, bu tÃ¼r kararlarÄ± insan deÄŸerleriyle uyumlu hale getirmeye odaklanÄ±yor; ama hangi â€œdeÄŸerlerinâ€ evrensel olduÄŸu hÃ¢lÃ¢ tartÄ±ÅŸmalÄ±.</p>
  
        <h3>3. GÃ¼Ã§, Sorumluluk ve ÅeffaflÄ±k</h3>
        <p>YZ sistemleri artÄ±k milyarlarca insanÄ±n hayatÄ±nÄ± etkileyen kararlar veriyor. Bu kadar gÃ¼Ã§lÃ¼ araÃ§larÄ±n etik kontrolÃ¼ de en az teknik gÃ¼venliÄŸi kadar Ã¶nemli.</p>
  
        <ul>
          <li><strong>ÅeffaflÄ±k:</strong> Bir algoritmanÄ±n nasÄ±l karar verdiÄŸini anlamak, onu sorgulayabilmek gerekir.</li>
          <li><strong>Sorumluluk:</strong> YanlÄ±ÅŸ bir kararÄ±n bedelini kim Ã¶deyecek?</li>
          <li><strong>Adalet:</strong> Verilerdeki Ã¶nyargÄ±lar nasÄ±l azaltÄ±lacak?</li>
        </ul>
  
        <p>Bu sorulara net yanÄ±tlar verilmeden, teknolojinin hÄ±zÄ±na gÃ¼venmek riskli olur.</p>
  
        <h3>4. Ä°nsan Merkezli Bir Gelecek</h3>
        <p>Belki de mesele, yapay zekÃ¢ya vicdan kazandÄ±rmak deÄŸil, vicdanÄ± olan insanlarÄ±n bu sistemleri nasÄ±l yÃ¶nettiÄŸi. Kodun satÄ±r aralarÄ±na â€œempatiâ€ yazmak mÃ¼mkÃ¼n deÄŸil; ama onu geliÅŸtirenlerin etik deÄŸerleri, sonuÃ§ta bu teknolojilerin kaderini belirliyor.</p>
  
        <p>Yapay zekÃ¢, insanlÄ±ÄŸÄ±n aynasÄ± gibi: ne kadar etik davranÄ±rsak, o kadar etik sonuÃ§lar Ã¼retir.</p>
  
        <h3>5. Son SÃ¶z</h3>
        <p>Kodun vicdanÄ± olmayabilir â€” ama onu yazanÄ±n vardÄ±r. Bu yÃ¼zden, geleceÄŸin yapay zekÃ¢sÄ± yalnÄ±zca daha akÄ±llÄ± deÄŸil, daha adil de olmalÄ±. GerÃ§ek ilerleme, yalnÄ±zca bilgiyle deÄŸil; sorumlulukla da Ã¶lÃ§Ã¼lÃ¼r.</p>
  
      </article>
  

    <a href="posts.html" class="btn secondary" style="margin-top: 2rem;">â† TÃ¼m YazÄ±lara DÃ¶n</a>
  </main>

  <footer class="footer">
    <div class="container">
      <div>Â© 2025 Science & Tech Voices</div>
    </div>
  </footer>
</body>
</html>
